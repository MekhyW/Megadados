{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistemas de armazenamento\n",
    "\n",
    "A escolha de sistemas de armazenamento é uma passo fundamental do gerenciamento eficiente em Big Data. Produzimos uma quantidade cada vez maior de dados diariamente, logo é imprescindível ter uma solução escalável e duradoura para armazenar tais informações, previnindo problemas tanto de performance quanto de proteção de dados sensíveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAID\n",
    "\n",
    "RAID (**R**edundant **A**rray of **I**nexpensive **D**isks) é uma tecnologia de armazenamento que consiste na combinação de vários discos rígidos em um único sistema. O RAID pode ser configurado de várias maneiras diferentes, chamadas de níveis RAID, que oferecem diferentes benefícios e compromissos entre capacidade de armazenamento, velocidade de leitura/gravação e tolerância a falhas. O objetivo principal do RAID é fornecer um meio mais seguro e **confiável** de armazenar **grandes quantidades de dados**, com **redundância** para minimizar a perda de dados em caso de falha do hardware.\n",
    "\n",
    "Vamos ver alguns níveis RAID.\n",
    "\n",
    "### RAID `0`\n",
    "\n",
    "O RAID 0 distribui os dados uniformemente em dois ou mais discos, sem informações de paridade, redundância ou tolerância a falhas. É normalmente usado para aumentar o desempenho, embora também possa ser usado como uma forma de criar um grande volume lógico a partir de dois ou mais discos físicos.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/9b/RAID_0.svg/300px-RAID_0.svg.png\">\n",
    "\n",
    "Fonte: https://upload.wikimedia.org/wikipedia/commons/thumb/9/9b/RAID_0.svg/300px-RAID_0.svg.png\n",
    "\n",
    "Como o RAID 0 não fornece tolerância a falhas ou redundância, a falha de uma unidade fará com que todo o array falhe; como resultado da distribuição de dados em todos os discos, a falha resultará na perda total de dados.\n",
    "\n",
    "### RAID `1`\n",
    "\n",
    "O RAID 1 é um tipo de configuração de armazenamento em que os dados são copiados (produz *mirror* ou clone) para dois ou mais discos rígidos separados, oferecendo uma solução de backup imediata caso um dos discos falhe.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b7/RAID_1.svg/300px-RAID_1.svg.png\">\n",
    "\n",
    "Fonte: https://upload.wikimedia.org/wikipedia/commons/thumb/b/b7/RAID_1.svg/300px-RAID_1.svg.png\n",
    "\n",
    "Nesta configuração, as solicitações de leitura podem ser atendidas e tratadas por qualquer unidade na matriz. Dependendo da natureza da carga de E/S, o desempenho de leitura aleatória de uma matriz RAID 1 pode ser igual à soma do desempenho de cada membro, enquanto o desempenho de gravação permanece no nível de um único disco.\n",
    "\n",
    "### RAID `5`\n",
    "\n",
    "O RAID 5 é um tipo de configuração de armazenamento que utiliza **três ou mais** discos rígidos para oferecer uma solução de armazenamento com desempenho e tolerância a falhas. Nessa configuração, os dados são distribuídos por todos os discos rígidos, o que permite que a leitura e gravação de dados ocorra de forma mais rápida.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/RAID_5.svg/600px-RAID_5.svg.png\">\n",
    "\n",
    "Fonte: https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/RAID_5.svg/600px-RAID_5.svg.png\n",
    "\n",
    "Além disso, o RAID 5 possui um esquema de paridade distribuída, onde um bloco de paridade é armazenado em cada disco do conjunto. Isso significa que se um dos discos falhar, as informações contidas nele podem ser reconstruídas usando os dados armazenados nos outros discos e nas informações de paridade, garantindo a integridade dos dados e permitindo que o sistema continue operando sem perda de informações.\n",
    "\n",
    "\n",
    "\n",
    "Veja mais em https://en.wikipedia.org/wiki/Standard_RAID_levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício 1**\n",
    "\n",
    "Suponha que precise mover os dados armazenados em 10000 HDs de 1TB cada. O novo servidor está a 600Km de distância. \n",
    "\n",
    "**a)** Explique como você resolveria este problema. Cite tecnologias adequadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Sua resposta AQUI!    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Qual seria a latência da sua solução?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Sua resposta AQUI!    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Qual a largura de banda e a taxa de transferência da sua solução?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Sua resposta AQUI!    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Suponha que você resolva colocar todos os HDs em um caminhão e disparar! Qual seria a latência e a taxa de transferência da solução?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Sua resposta AQUI!    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício 2** (*Prova Final 2019-2*)\n",
    "\n",
    "Em um cluster temos vários arquivos enormes, de tamanho médio 1 GB. Todos os arquivos são do tipo write-once-read-many: uma vez que o arquivo é criado, ele pode apenas ser removido por completo, nunca modificado parcialmente. Esse é o modo de operação do S3 da AWS. \n",
    "Os arquivos são divididos em blocos de 64 MB e estão armazenados de modo redundante, com fator de replicação 3 (este é o modo padrão do HDFS). Ou seja, cada bloco é armazenado 3 vezes, em máquinas diferentes. \n",
    "Desejamos armazenar 10000 arquivos destes, em máquinas com 4 discos de 1TB SSD cada, nas quais queremos que os dados ocupem no máximo 75% do espaço. \n",
    "Toda semana parte dos arquivos será processada usando Spark para alguma atividade de extração de informação. \n",
    "\n",
    "**a)** Quais as vantagens e desvantagens da replicação em máquinas diferentes, neste contexto? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Sua resposta AQUI!    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Porque write-once-read-many é desejável aqui? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Sua resposta AQUI!    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Quantas máquinas este cluster deve ter, no mínimo, para acomodar esses dados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Sua resposta AQUI!    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Mais dados chegam constantemente ao sistema, que eventualmente ficará sem capacidade! Mas uma vez que a pipeline Spark é executada, os dados não são mais necessários de imediato. Proponha uma solução simples para não perder dados e não ter que aumentar indefinidamente o cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Sua resposta AQUI!    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício 3** (*Prova Final 2018-2*)\n",
    "\n",
    "Descreva um sistema de armazenamento adequado para edição de vídeo, onde temos grandes massas de dados e a necessidade de transferi-los em alta velocidade numa rede local. \n",
    "\n",
    "Estime capacidade e velocidade de transferência para editar vídeos full HD (1920x1080, 30 quadros por segundo, 24-bit RGB) com taxa de compressão típica de 30% (ou seja, o tamanho comprimido é 30% do tamanho original). \n",
    "\n",
    "Cite tecnologias adequadas para este sistema. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Sua resposta AQUI!    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício 4** (*Prova Final 2017-2*)\n",
    "\n",
    "(contexto: nesta prova estávamos falando de uma rede social fictícia da start-up na qual você trabalha)\n",
    "\n",
    "A rede social está fazendo um sucesso inacreditável! Estima-se que daqui a 6 meses a rede terá 2 milhões de usuários, cada um postando uma média de 10kB por dia de conteúdo (fotos, áudio, texto, etc). Pelas regras desta rede social, todo o material postado nos últimos 12 meses estará rapidamente acessível, (em questão de milissegundos). A empresa deseja manter registros históricos de todo o material mais antigo (após 12 meses), indefinidamente. Projete uma solução de armazenamento para a empresa, indicando o tamanho esperado do(s) espaço(s) de armazenamento. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Sua resposta AQUI!    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício 5** Considerando a capacidade total de todos os discos, qual a porcentagem aproximada realmente disponível para armazenamento no RAID 0, RAID 1 e RAID 5 (considere 4 discos)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Sua resposta AQUI!    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício 6**\n",
    "\n",
    "Neste exercício vamos trabalhar com o AWS S3 utilizando a biblioteca `boto3`.\n",
    "\n",
    "**a)** Faça a instalação dela com `pip install boto3`.\n",
    "\n",
    "**b)** Utilize as credenciais disponibilizadas pelo professor para criar um `.env` na pasta da aula de hoje. Cuidado para não vazar estas credenciais, jamais disponibilize no github ou qualquer outro lugar público! Estas credenciais estarão válidas apenas durante a aula de hoje.\n",
    "\n",
    "**c)** Vamos enviar uma imagem para o S3. Para isto, considere o arquivo `an_dalle.jpeg` gerado no bing utilizando o promp \"an\" (vai entender como este prompt gerou esta imagem, mas gostei!).\n",
    "\n",
    "<img src=\"an_dalle.jpeg\">\n",
    "\n",
    "A imagem deverá ser salva em `\"bucket/USUARIO_INSPER/an_dalle.jpeg\"`. Assim cada aluno consegue escrever e ler sem prejudicar os demais, uma vez que utilizaremos o mesmo bucket S3.\n",
    "\n",
    "Preencha seu usuário Insper no código e execute.\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# Carrega variáveis de ambiente, confira seu .env\n",
    "load_dotenv()\n",
    "\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    ")\n",
    "\n",
    "# Na pasta da aula deve existir este arquivo\n",
    "fname = \"an_dalle.jpeg\"\n",
    "\n",
    "# Informe seu usuário insper para diferenciar, no bucket s3, o seu conteúdo\n",
    "# e o de seus colegas\n",
    "insper_username = \"\" # <--- Seu usuário Insper AQUI!\n",
    "bucket_name = os.getenv(\"AWS_BUCKET_NAME\")\n",
    "\n",
    "# A chave serve como um prefixo + arquivo (como em um sistema de pastas)\n",
    "key = f\"{insper_username}/{fname}\"\n",
    "\n",
    "# Faz o upload do arquivo para o bucket\n",
    "s3.upload_file(fname, bucket_name, key)\n",
    "print(\"Fez o upload!\")\n",
    "```\n",
    "\n",
    "**d)** Agora vamos conferir se conseguimos fazer a leitura da imagem.\n",
    "\n",
    "Preencha seu usuário Insper no código a seguir e confira se a imagem `an_dalle_downloaded.jpeg` é gerada corretamente.\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carrega variáveis de ambiente, confira seu .env\n",
    "load_dotenv()\n",
    "\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    ")\n",
    "\n",
    "# Este é o arquivo que você quer baixar\n",
    "fname = \"an_dalle.jpeg\"\n",
    "insper_username = \"\" # <--- Seu usuário Insper AQUI!\n",
    "bucket_name = os.getenv(\"AWS_BUCKET_NAME\")\n",
    "\n",
    "# Com qual prefixo o arquivo está armazenado no bucket s3\n",
    "key = f\"{insper_username}/{fname}\"\n",
    "\n",
    "# Este será o nome do arquivo baixado\n",
    "local_file_path = \"an_dalle_downloaded.jpeg\"\n",
    "\n",
    "# Faz download do arquivo\n",
    "s3.download_file(bucket_name, key, local_file_path)\n",
    "print(f\"Fez o download, confira o arquivo {local_file_path}\")\n",
    "```\n",
    "\n",
    "**e)** Como funcionou para o `.jepg`, vamos utilizar a mesma ideia para subir no S3 um backup de uma base MySQL.\n",
    "\n",
    "Para isto, utilizaremos o `mysqldump`. Provavelmente o executável `mysqldump.exe` está na pasta `C:\\Program Files\\MySQL\\MySQL Server 8.0\\bin`. Localize o local correto e faça a adição dele ao `PATH` do sistema caso ainda não esteja.\n",
    "\n",
    "Em seguida, abra o terminal e faça o backup da base `classicmodels`:\n",
    "\n",
    "```console\n",
    "mysqldump -h localhost -u root -p classicmodels > classicmodels_261023.sql\n",
    "```\n",
    "\n",
    "Então, adapte o código para enviar este arquivo SQL para o S3, deixando-o em `\"bucket/USUARIO_INSPER/classicmodels_261023.sql\"`.\n",
    "\n",
    "Em seguida, adapte o código de download para baixar o arquivo SQL como `classicmodels_261023_downloaded.sql`.\n",
    "\n",
    "Então, faremos a reconstrução da base. Faremos drop com:\n",
    "\n",
    "```console\n",
    "mysql -h localhost -P 3306 -u root -p -e \"DROP DATABASE classicmodels;\"\n",
    "```\n",
    "\n",
    "Você pode abrir o Workbench e conferir se o drop realmente ocorreu!\n",
    "\n",
    "Crie o database novamente com:\n",
    "\n",
    "```console\n",
    "mysql -h localhost -P 3306 -u root -p -e \"CREATE DATABASE classicmodels;\"\n",
    "```\n",
    "\n",
    "E reconstrua as tabelas e dados com:\n",
    "\n",
    "```console\n",
    "mysql -h localhost -P 3306 -u root -p classicmodels < classicmodels_261023_downloaded.sql\n",
    "```\n",
    "\n",
    "Pronto! Abra o workbench e confira se a base foi restaurada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gabarito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<div id=\"gab_ex1\">**Exercício 1 d)**</div>**\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Vamos ignorar o tempo para desmontar e remontar os HDs (senão perde toda a graça!)...\n",
    "Supondo que o caminhão viaja em média a 75 Km/h, então levará 8 horas para chegar ao destino. Logo, a latência é de aproximadamente 8 horas!\n",
    "\n",
    "A taxa de transferência é a quantidade transmitida dividido pelo tempo. Então vamos considerar GB e segundos como unidades.\n",
    "\n",
    "```python\n",
    "    qtde_hds = 10000 # Quantos HDs eu quero transferir\n",
    "    tb = qtde_hds * 1 # Cada HD tem 1TB, então calculamos o total de TB a serem transferidos\n",
    "    gb = tb * 1024 # Converte TB para GB \n",
    "\n",
    "    horas = 8\n",
    "    segundos = horas * 60 * 60\n",
    "\n",
    "    throughput = gb / segundos\n",
    "    throughput\n",
    "```\n",
    "Resultado: taxa de transferência de 355.56 GB/s\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**<div id=\"gab_ex2\">**Exercício 2**</div>**\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**a)**\n",
    "\n",
    "Vantagens:\n",
    "\n",
    "- confiabilidade: se uma máquina cai, o sistema continua a rodar\n",
    "- Desempenho: propicia acesso paralelo aos dados\n",
    "\n",
    "Desvantagens:\n",
    "- Custo de aquisição dos equipamentos\n",
    "- Custo de operação\n",
    "\n",
    "**b)**\n",
    "    \n",
    "É comum em BigData que ocorra apenas a leitura de dados brutos:\n",
    "    \n",
    "Dados brutos -> pipeline de processamentos -> dados processados -> Análise\n",
    "\n",
    "Caso necessário, os resultados da análise são armazenados, mas os dados originais são comumente mantidos.\n",
    "\n",
    "Além disso, não precisamos sincronizar dados entre cópias, o que facilita replicação de dados para desempenho e confiabilidade.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**<div id=\"gab_ex4\">**Exercício 4**</div>**\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "*(Resposta parcial)*\n",
    "\n",
    "Uma solução para teria as seguintes características propostas:\n",
    "\n",
    "- write-once-read-many: é raro querer editar posts, só postar, raramente deletar\n",
    "- 12 meses de dados \"live\", o resto é backup\n",
    "    \n",
    "Uma solução seria utilizar o S3 para manter os dados live e o Glacier para os dados mais antigos (backup). Os dados poderiam ser restaurados do Glacier caso fosse necessário fazer auditoria.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referências\n",
    "- Silberschatz cap. 11\n",
    "- Parte dos textos gerados utilizando https://chatbot.theb.ai/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
